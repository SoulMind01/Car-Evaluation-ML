{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 25 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   0_high   1728 non-null   int64\n",
      " 1   0_low    1728 non-null   int64\n",
      " 2   0_med    1728 non-null   int64\n",
      " 3   0_vhigh  1728 non-null   int64\n",
      " 4   1_high   1728 non-null   int64\n",
      " 5   1_low    1728 non-null   int64\n",
      " 6   1_med    1728 non-null   int64\n",
      " 7   1_vhigh  1728 non-null   int64\n",
      " 8   2_2      1728 non-null   int64\n",
      " 9   2_3      1728 non-null   int64\n",
      " 10  2_4      1728 non-null   int64\n",
      " 11  2_5more  1728 non-null   int64\n",
      " 12  3_2      1728 non-null   int64\n",
      " 13  3_4      1728 non-null   int64\n",
      " 14  3_more   1728 non-null   int64\n",
      " 15  4_big    1728 non-null   int64\n",
      " 16  4_med    1728 non-null   int64\n",
      " 17  4_small  1728 non-null   int64\n",
      " 18  5_high   1728 non-null   int64\n",
      " 19  5_low    1728 non-null   int64\n",
      " 20  5_med    1728 non-null   int64\n",
      " 21  6_acc    1728 non-null   int64\n",
      " 22  6_good   1728 non-null   int64\n",
      " 23  6_unacc  1728 non-null   int64\n",
      " 24  6_vgood  1728 non-null   int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 337.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_high</th>\n",
       "      <th>0_low</th>\n",
       "      <th>0_med</th>\n",
       "      <th>0_vhigh</th>\n",
       "      <th>1_high</th>\n",
       "      <th>1_low</th>\n",
       "      <th>1_med</th>\n",
       "      <th>1_vhigh</th>\n",
       "      <th>2_2</th>\n",
       "      <th>2_3</th>\n",
       "      <th>...</th>\n",
       "      <th>4_big</th>\n",
       "      <th>4_med</th>\n",
       "      <th>4_small</th>\n",
       "      <th>5_high</th>\n",
       "      <th>5_low</th>\n",
       "      <th>5_med</th>\n",
       "      <th>6_acc</th>\n",
       "      <th>6_good</th>\n",
       "      <th>6_unacc</th>\n",
       "      <th>6_vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_high  0_low  0_med  0_vhigh  1_high  1_low  1_med  1_vhigh  2_2  2_3  \\\n",
       "0      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "1      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "2      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "3      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "4      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "\n",
       "   ...  4_big  4_med  4_small  5_high  5_low  5_med  6_acc  6_good  6_unacc  \\\n",
       "0  ...     -1     -1        1      -1      1     -1     -1      -1        1   \n",
       "1  ...     -1     -1        1      -1     -1      1     -1      -1        1   \n",
       "2  ...     -1     -1        1       1     -1     -1     -1      -1        1   \n",
       "3  ...     -1      1       -1      -1      1     -1     -1      -1        1   \n",
       "4  ...     -1      1       -1      -1     -1      1     -1      -1        1   \n",
       "\n",
       "   6_vgood  \n",
       "0       -1  \n",
       "1       -1  \n",
       "2       -1  \n",
       "3       -1  \n",
       "4       -1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from the file\n",
    "data = pd.read_csv('car+evaluation/car.data', header=None)\n",
    "data = pd.get_dummies(data)\n",
    "data.iloc[:,:] = data.iloc[:,:].replace({False: -1, True: 1})\n",
    "# Display the first few rows of the dataset\n",
    "data.info()\n",
    "data.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feat_num = data.shape[1] - 4\n",
    "columns = [i for i in range(feat_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data.iloc[:, columns], data.iloc[:, 21], test_size=0.3)\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, y, sigma=1.0):\n",
    "    return np.exp(-np.linalg.norm(x - y) ** 2 / (2 * (sigma ** 2)))\n",
    "def linear_kernel(x, y):\n",
    "    return np.dot(x, y)\n",
    "def polynomial_kernel(x, y, c=1, d=7):\n",
    "    return (np.dot(x, y) + c) ** d\n",
    "def laplacian_kernel(x, y, sigma=1):\n",
    "    return np.exp(-np.linalg.norm(x - y) / sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_kernel_svm(X_train, y_train, X_test, y_test, C = 1, kernel='gaussian'):\n",
    "    if kernel == 'gaussian':\n",
    "        kernel_matrix = np.array([[gaussian_kernel(x, y) for y in train_X] for x in train_X])\n",
    "    elif kernel == 'linear':\n",
    "        kernel_matrix = np.array([[linear_kernel(x, y) for y in train_X] for x in train_X])\n",
    "    elif kernel == 'polynomial':\n",
    "        kernel_matrix = np.array([[polynomial_kernel(x, y) for y in train_X] for x in train_X])\n",
    "    elif kernel == 'laplacian':\n",
    "        kernel_matrix = np.array([[laplacian_kernel(x, y) for y in train_X] for x in train_X])\n",
    "    alpha = cp.Variable((train_X.shape[0],1))\n",
    "    outer_y = train_y.values.reshape((-1,1)) * train_y.values.reshape((-1,1)).T\n",
    "    gram = outer_y * kernel_matrix\n",
    "    objective = cp.Minimize(-cp.sum(alpha) + 0.5 * cp.quad_form(alpha, cp.psd_wrap(gram)))\n",
    "    constraints = [0 <= alpha, alpha <= C, train_y.values @ alpha == 0]\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver = cp.SCS)\n",
    "    print(\"problem status: \",problem.status)\n",
    "    test_kernel_matrix = np.array([[gaussian_kernel(x, y) for y in test_X] for x in train_X])\n",
    "    predictions = np.sign(np.sum(train_y.values.reshape((-1,1)) * alpha.value * test_kernel_matrix, axis=0))\n",
    "    accuracy = np.mean(predictions == test_y.values)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n",
      "Accuracy: 0.8342967244701349\n"
     ]
    }
   ],
   "source": [
    "train_kernel_svm(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n",
      "Accuracy: 0.630057803468208\n"
     ]
    }
   ],
   "source": [
    "train_kernel_svm(train_X, train_y, test_X, test_y, kernel= 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n",
      "Accuracy: 0.8208092485549133\n"
     ]
    }
   ],
   "source": [
    "train_kernel_svm(train_X, train_y, test_X, test_y, kernel= 'polynomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n",
      "Accuracy: 0.7976878612716763\n"
     ]
    }
   ],
   "source": [
    "train_kernel_svm(train_X, train_y, test_X, test_y, kernel= 'laplacian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier with a soft margin\n",
    "def train_linear_svm(X_train, y_train, X_test, y_test, gamma = 0.001, norm = 1):\n",
    "    # m is the number of training examples\n",
    "    m = X_train.shape[0]\n",
    "    # n is the number of features\n",
    "    n = X_train.shape[1]\n",
    "    # Need to train k different classifiers\n",
    "    k = y_train.shape[1]\n",
    "    predict_train = np.zeros((k,m,1))\n",
    "    predict_test = np.zeros((k,X_test.shape[0],1))\n",
    "    for i in range(k):\n",
    "        y = y_train[:,i].reshape((-1,1))\n",
    "        w = cp.Variable((n,1))\n",
    "        b = cp.Variable()\n",
    "        eta = cp.Variable((m,1))\n",
    "        norm_eta = cp.norm1(eta) if norm == 1 else cp.norm2(eta)\n",
    "        const = np.ones((m,1))\n",
    "        objective = cp.Minimize(cp.norm2(w) + gamma * norm_eta)\n",
    "        constraints = [cp.multiply(y, X_train @ w - b) >= const - eta, eta >= 0]\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve(verbose=False)\n",
    "        predict_train[i] = np.sign((X_train @ w.value - b.value * const))\n",
    "        predict_test[i] = np.sign((X_test @ w.value - b.value * np.ones((X_test.shape[0],1))))\n",
    "    predict_train = np.squeeze(predict_train.T)\n",
    "    accuracy_train = np.mean(np.all(predict_train == y_train, axis=1))\n",
    "    accuracy_train = round(accuracy_train, 3)\n",
    "    predict_test = np.squeeze(predict_test.T)\n",
    "    accuracy_test = np.mean(np.all(predict_test == y_test, axis=1))\n",
    "    accuracy_test = round(accuracy_test, 3)\n",
    "\n",
    "    return accuracy_train, accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_linear_svm(data_path = 'car+evaluation/car.data'):\n",
    "    data = pd.read_csv(data_path, header=None)\n",
    "    data = pd.get_dummies(data)\n",
    "    # Change the false labels to -1 in last 4 columns\n",
    "    data.iloc[:,:] = data.iloc[:,:].replace({False: -1, True: 1})\n",
    "    train_ratio = 0.8\n",
    "    X_train = data.iloc[:int(train_ratio * data.shape[0]),:-4].values\n",
    "    y_train = data.iloc[:int(train_ratio * data.shape[0]),-4:].values\n",
    "    X_test = data.iloc[int(train_ratio * data.shape[0]):,:-4].values\n",
    "    y_test = data.iloc[int(train_ratio * data.shape[0]):,-4:].values\n",
    "    gamma_list = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "    norms = [1, 2]\n",
    "    history = []\n",
    "    for norm in norms:\n",
    "        for gamma in gamma_list:\n",
    "            accuracy_train, accuracy_test = train_linear_svm(X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, gamma = gamma, norm = norm)\n",
    "            history.append([norm, gamma, accuracy_train, accuracy_test])\n",
    "    for row in history:\n",
    "        print('norm: {}, gamma: {}, train accuracy: {}, test accuracy: {}'.format(row[0], row[1], row[2], row[3]))\n",
    "    # Find the best test accuracy row\n",
    "    best_row = history[np.argmax(np.array(history)[:,-1])]\n",
    "    print('best test accuracy: {:<10} training accuracy: {:<10} norm: {:<10} gamma: {:<10}'.format(best_row[3], best_row[2], best_row[0], best_row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vote_svm(X_train, X_test, y_train, y_test, gamma, eta_norm):\n",
    "    # Number of training examples\n",
    "    m = X_train.shape[0]\n",
    "    # Number of features\n",
    "    n = X_train.shape[1]\n",
    "    # Number of classes\n",
    "    k = 4\n",
    "    \n",
    "    # Initialize the predictions matrix\n",
    "    train_predictions = np.zeros((m, 6))\n",
    "    test_predictions = np.zeros((X_test.shape[0], 6))\n",
    "    \n",
    "    # Train k*(k-1)/2 SVM models\n",
    "    model_index = 0\n",
    "    for i in range(k):\n",
    "        for j in range(i+1, k):\n",
    "            # Select the samples for the current pair of classes\n",
    "            X_train_pair = X_train[np.logical_or(y_train == i, y_train == j)]\n",
    "            y_train_pair = y_train[np.logical_or(y_train == i, y_train == j)]\n",
    "            y_train_pair = np.where(y_train_pair == i, -1, 1).reshape((-1,1))\n",
    "            \n",
    "            X_test_pair = X_test[np.logical_or(y_test == i, y_test == j)]\n",
    "            y_test_pair = y_test[np.logical_or(y_test == i, y_test == j)]\n",
    "            y_test_pair = np.where(y_test_pair == i, -1, 1).reshape((-1,1))\n",
    "            if(X_train_pair.shape[0] == 0):\n",
    "                continue\n",
    "            # Variables\n",
    "            w = cp.Variable((n,1))\n",
    "            b = cp.Variable()\n",
    "            eta = cp.Variable((X_train_pair.shape[0],1))\n",
    "            \n",
    "            # Constraints\n",
    "            constraints = [cp.multiply(y_train_pair, X_train_pair @ w - b) >= 1 - eta, eta >= 0]\n",
    "            \n",
    "            # Objective function\n",
    "            objective = cp.Minimize(cp.norm2(w) + gamma * cp.norm(eta, eta_norm))\n",
    "            \n",
    "            # Problem definition\n",
    "            problem = cp.Problem(objective, constraints)\n",
    "            \n",
    "            # Solve the problem\n",
    "            problem.solve()\n",
    "            \n",
    "            # Get the optimal values\n",
    "            w_opt = w.value.reshape((-1,1))\n",
    "            b_opt = b.value\n",
    "            \n",
    "            # Calculate the predictions for training and test data\n",
    "            train_predictions[:, model_index] = np.sign(X_train @ w_opt - b_opt).reshape((-1,))\n",
    "            test_predictions[:, model_index] = np.sign(X_test @ w_opt - b_opt).reshape((-1,))\n",
    "            # If the prediction is negative, the class is i, otherwise it is j\n",
    "            # Change the prediction value into i or j\n",
    "            train_predictions[:, model_index] = np.where(train_predictions[:, model_index] == -1, i, j)\n",
    "            test_predictions[:, model_index] = np.where(test_predictions[:, model_index] == -1, i, j)\n",
    "            \n",
    "            \n",
    "            model_index += 1\n",
    "    \n",
    "    # Calculate the final predictions by majority voting\n",
    "    # If there is a tie, choose the class with the smallest index\n",
    "    train_final_predictions = np.zeros((m,))\n",
    "    test_final_predictions = np.zeros((X_test.shape[0],))\n",
    "    for i in range(m):\n",
    "        train_final_predictions[i] = np.argmax(np.bincount(train_predictions[i,:].astype('int')))\n",
    "    for i in range(X_test.shape[0]):\n",
    "        test_final_predictions[i] = np.argmax(np.bincount(test_predictions[i,:].astype('int')))\n",
    "    \n",
    "    # Calculate the accuracies\n",
    "    train_accuracy = np.mean(train_final_predictions == y_train)\n",
    "    test_accuracy = np.mean(test_final_predictions == y_test)\n",
    "    train_accuracy = round(train_accuracy, 3)\n",
    "    test_accuracy = round(test_accuracy, 3)\n",
    "    \n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "def train_svm_with_parameters(data_path = 'car+evaluation/car.data'):\n",
    "    data = pd.read_csv(data_path, header=None)\n",
    "    # Change each string value to a unique integer\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype('category').cat.codes\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    \n",
    "    train_ratio = 0.8\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-train_ratio)\n",
    "    \n",
    "    gamma_list = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "    eta_norms = [1, 2]\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for gamma in gamma_list:\n",
    "        for eta_norm in eta_norms:\n",
    "            train_accuracy, test_accuracy = train_vote_svm(X_train, X_test, y_train, y_test, gamma, eta_norm)\n",
    "            history.append([eta_norm, gamma, train_accuracy, test_accuracy])\n",
    "    for row in history:\n",
    "        print('norm: {}, gamma: {}, train accuracy: {}, test accuracy: {}'.format(row[0], row[1], row[2], row[3]))\n",
    "    # Find the best test accuracy row\n",
    "    best_row = history[np.argmax(np.array(history)[:,-1])]\n",
    "    print('best test accuracy: {:<10} training accuracy: {:<10} norm: {:<10} gamma: {:<10}'.format(best_row[3], best_row[2], best_row[0], best_row[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11709\\anaconda3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1, gamma: 0.001, train accuracy: 0.732, test accuracy: 0.572\n",
      "norm: 1, gamma: 0.003, train accuracy: 0.722, test accuracy: 0.566\n",
      "norm: 1, gamma: 0.01, train accuracy: 0.874, test accuracy: 0.708\n",
      "norm: 1, gamma: 0.03, train accuracy: 0.891, test accuracy: 0.647\n",
      "norm: 1, gamma: 0.1, train accuracy: 0.886, test accuracy: 0.699\n",
      "norm: 1, gamma: 0.3, train accuracy: 0.886, test accuracy: 0.717\n",
      "norm: 1, gamma: 1, train accuracy: 0.885, test accuracy: 0.728\n",
      "norm: 1, gamma: 3, train accuracy: 0.885, test accuracy: 0.734\n",
      "norm: 1, gamma: 10, train accuracy: 0.885, test accuracy: 0.734\n",
      "norm: 1, gamma: 30, train accuracy: 0.885, test accuracy: 0.734\n",
      "norm: 2, gamma: 0.001, train accuracy: 0.732, test accuracy: 0.572\n",
      "norm: 2, gamma: 0.003, train accuracy: 0.732, test accuracy: 0.572\n",
      "norm: 2, gamma: 0.01, train accuracy: 0.732, test accuracy: 0.572\n",
      "norm: 2, gamma: 0.03, train accuracy: 0.732, test accuracy: 0.572\n",
      "norm: 2, gamma: 0.1, train accuracy: 0.789, test accuracy: 0.584\n",
      "norm: 2, gamma: 0.3, train accuracy: 0.876, test accuracy: 0.72\n",
      "norm: 2, gamma: 1, train accuracy: 0.873, test accuracy: 0.723\n",
      "norm: 2, gamma: 3, train accuracy: 0.87, test accuracy: 0.723\n",
      "norm: 2, gamma: 10, train accuracy: 0.87, test accuracy: 0.728\n",
      "norm: 2, gamma: 30, train accuracy: 0.869, test accuracy: 0.728\n",
      "best test accuracy: 0.734      training accuracy: 0.885      norm: 1          gamma: 3         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11709\\anaconda3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1, gamma: 0.001, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 2, gamma: 0.001, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 1, gamma: 0.003, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 2, gamma: 0.003, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 1, gamma: 0.01, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 2, gamma: 0.01, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 1, gamma: 0.03, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 2, gamma: 0.03, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 1, gamma: 0.1, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 2, gamma: 0.1, train accuracy: 0.699, test accuracy: 0.705\n",
      "norm: 1, gamma: 0.3, train accuracy: 0.726, test accuracy: 0.72\n",
      "norm: 2, gamma: 0.3, train accuracy: 0.706, test accuracy: 0.699\n",
      "norm: 1, gamma: 1, train accuracy: 0.729, test accuracy: 0.72\n",
      "norm: 2, gamma: 1, train accuracy: 0.708, test accuracy: 0.685\n",
      "norm: 1, gamma: 3, train accuracy: 0.729, test accuracy: 0.72\n",
      "norm: 2, gamma: 3, train accuracy: 0.716, test accuracy: 0.694\n",
      "norm: 1, gamma: 10, train accuracy: 0.729, test accuracy: 0.72\n",
      "norm: 2, gamma: 10, train accuracy: 0.714, test accuracy: 0.688\n",
      "norm: 1, gamma: 30, train accuracy: 0.729, test accuracy: 0.72\n",
      "norm: 2, gamma: 30, train accuracy: 0.713, test accuracy: 0.688\n",
      "best test accuracy: 0.72       training accuracy: 0.726      norm: 1          gamma: 0.3       \n"
     ]
    }
   ],
   "source": [
    "train_best_linear_svm()\n",
    "train_svm_with_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
