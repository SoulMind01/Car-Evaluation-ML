{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Dec 06 12:09:45 PM: Encountered unexpected exception importing solver OSQP:\n",
      "ImportError('DLL load failed while importing qdldl: 找不到指定的模块。')\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1  2  3      4     5      6\n",
      "0  vhigh  vhigh  2  2  small   low  unacc\n",
      "1  vhigh  vhigh  2  2  small   med  unacc\n",
      "2  vhigh  vhigh  2  2  small  high  unacc\n",
      "3  vhigh  vhigh  2  2    med   low  unacc\n",
      "4  vhigh  vhigh  2  2    med   med  unacc\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1728 non-null   object\n",
      " 1   1       1728 non-null   object\n",
      " 2   2       1728 non-null   object\n",
      " 3   3       1728 non-null   object\n",
      " 4   4       1728 non-null   object\n",
      " 5   5       1728 non-null   object\n",
      " 6   6       1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from the file\n",
    "data = pd.read_csv('car+evaluation/car.data', header=None)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "data.info()\n",
    "data[6].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all columns to numeric\n",
    "for i in range(0, 6):\n",
    "    data[i] = pd.Categorical(data[i])\n",
    "    data[i] = data[i].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.33333333, 0.66666667, 1.        , 0.5       ,\n",
       "        0.5       ],\n",
       "       [0.        , 1.        , 0.        , 0.5       , 0.5       ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.66666667, 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.5       , 0.5       ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 0.33333333, 1.        , 0.        ,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = [0,1,2,3,4,5]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[columns], data[6].replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}), test_size=0.3)\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.21701739, 0.44683961, ..., 0.16901332, 0.16438311,\n",
       "        0.32465247],\n",
       "       [0.21701739, 1.        , 0.30287217, ..., 0.33846543, 0.58991444,\n",
       "        0.66846063],\n",
       "       [0.44683961, 0.30287217, 1.        , ..., 0.37824157, 0.36787944,\n",
       "        0.39433457],\n",
       "       ...,\n",
       "       [0.16901332, 0.33846543, 0.37824157, ..., 1.        , 0.73671398,\n",
       "        0.17620431],\n",
       "       [0.16438311, 0.58991444, 0.36787944, ..., 0.73671398, 1.        ,\n",
       "        0.39433457],\n",
       "       [0.32465247, 0.66846063, 0.39433457, ..., 0.17620431, 0.39433457,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_kernel(x, y, sigma=1.0):\n",
    "    return np.exp(-np.linalg.norm(x - y) ** 2 / (2 * (sigma ** 2)))\n",
    "def linear_kernel(x, y):\n",
    "    return np.dot(x, y)\n",
    "kernel_matrix = np.array([[gaussian_kernel(x, y) for y in train_X] for x in train_X])\n",
    "kernel_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n"
     ]
    }
   ],
   "source": [
    "alpha = cp.Variable((train_X.shape[0],1))\n",
    "outer_y = train_y.values.reshape((-1,1)) * train_y.values.reshape((-1,1)).T\n",
    "gram = outer_y * kernel_matrix\n",
    "objective = cp.Minimize(-cp.sum(alpha) + 0.5 * cp.quad_form(alpha, cp.psd_wrap(gram)))\n",
    "constraints = [0 <= alpha, alpha <= 1, train_y.values @ alpha == 0]\n",
    "\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(solver = cp.SCS)\n",
    "print(\"problem status: \",problem.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pridiction_type (array([-1.,  1.]), array([217, 302], dtype=int64))\n",
      "Accuracy: 0.6955684007707129\n"
     ]
    }
   ],
   "source": [
    "# support_vector_indices = np.where(alpha.value > 1e-5)[0]\n",
    "# support_vectors = train_X[support_vector_indices]\n",
    "# support_vector_labels = train_y.values[support_vector_indices]\n",
    "\n",
    "test_kernel_matrix = np.array([[gaussian_kernel(x, y) for y in test_X] for x in train_X])\n",
    "predictions = np.sign(np.sum(train_y.values.reshape((-1,1)) * alpha.value * test_kernel_matrix, axis=0))\n",
    "print('pridiction_type',np.unique(predictions,return_counts=True))\n",
    "accuracy = np.mean(predictions == test_y.values)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_list = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 1]\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[columns], data[6], test_size=0.1)\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the SVM classifier\n",
    "def train_svm(X_train, y_train, X_test, y_test, gamma):\n",
    "    m = X_train.shape[0]\n",
    "    n = X_train.shape[1]\n",
    "    y_train = y_train.reshape((-1,1))\n",
    "    y_test = y_test.reshape((-1,1))\n",
    "    # L1 norm\n",
    "    w1 = cp.Variable((n,1))\n",
    "    b1 = cp.Variable()\n",
    "    n1 = cp.Variable((m,1))\n",
    "    const = np.ones((m,1))\n",
    "    constraints1 = [cp.multiply(y_train, (X_train @ w1 + b1)) >= const - n1, n1 >= 0]\n",
    "    objective1 = cp.Minimize(cp.norm1(w1) + gamma * cp.norm1(n1))\n",
    "    problem1 = cp.Problem(objective1, constraints1)\n",
    "    problem1.solve(verbose=False)\n",
    "    predictions1 = np.sign(X_test @ w1.value + b1.value)\n",
    "    accuracy1 = np.mean(predictions1 == y_test)\n",
    "\n",
    "    # L2 norm\n",
    "    w2 = cp.Variable((n,1))\n",
    "    b2 = cp.Variable()\n",
    "    n2 = cp.Variable((m,1))\n",
    "    constraints2 = [cp.multiply(y_train, (X_train @ w2 + b2)) >= const - n2, n2 >= 0]\n",
    "    objective2 = cp.Minimize(cp.norm2(w2) + gamma * cp.norm1(n2))\n",
    "    problem2 = cp.Problem(objective2, constraints2)\n",
    "    problem2.solve(verbose=False)\n",
    "    predictions2 = np.sign(X_test @ w2.value + b2.value)\n",
    "    accuracy2 = np.mean(predictions2 == y_test)\n",
    "\n",
    "\n",
    "    best_w = w1.value if accuracy1 > accuracy2 else w2.value\n",
    "    best_b = b1.value if accuracy1 > accuracy2 else b2.value\n",
    "    best_accuracy = accuracy1 if accuracy1 > accuracy2 else accuracy2\n",
    "    return best_w, best_b, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(X_train, y_train, X_test, y_test):\n",
    "    best_accuracy = 0\n",
    "    best_w = None\n",
    "    best_b = None\n",
    "    for gamma in gamma_list:\n",
    "        w, b, accuracy = train_svm(X_train, y_train, X_test, y_test, gamma)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_w = w\n",
    "            best_b = b\n",
    "    return best_w, best_b, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different values of gamma\n",
    "def train_general():\n",
    "    # Train a SVM classifier, suppose acceptable is -1 and unacceptable, good, very good are 1\n",
    "    train_y1 = train_y.replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}).values\n",
    "    test_y1 = test_y.replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}).values\n",
    "    best_w1, best_b1, best_accuracy = get_best_model(train_X, train_y1, test_X, test_y1)\n",
    "    print('predict_y1_types', np.unique(np.sign(test_X @ best_w1 + best_b1), return_counts=True))\n",
    "    print(f\"Accuracy: {best_accuracy}\")\n",
    "\n",
    "def train_vote():\n",
    "    \n",
    "    # Train a SVM classifier, suppose unacceptable is -1 and acceptable is 1\n",
    "    train_y2 = train_y[~train_y.isin(['good', 'vgood'])].replace({'unacc': -1, 'acc': 1}).values\n",
    "    test_y2 = test_y[~test_y.isin(['good', 'vgood'])].replace({'unacc': -1, 'acc': 1}).values\n",
    "    train_X2 = train_X[~train_y.isin(['good', 'vgood'])]\n",
    "    test_X2 = test_X[~test_y.isin(['good', 'vgood'])]\n",
    "    w2, b2, _ = get_best_model(train_X2, train_y2, test_X2, test_y2)\n",
    "    print('predict_y2_types', np.unique(np.sign(test_X2 @ w2 + b2), return_counts=True))\n",
    "    \n",
    "    # Train a SVM classifier, suppose unacceptable is -1 and good is 1\n",
    "    train_y3 = train_y[~train_y.isin(['acc', 'vgood'])].replace({'unacc': -1, 'good': 1}).values\n",
    "    test_y3 = test_y[~test_y.isin(['acc', 'vgood'])].replace({'unacc': -1, 'good': 1}).values\n",
    "    train_X3 = train_X[~train_y.isin(['acc', 'vgood'])]\n",
    "    test_X3 = test_X[~test_y.isin(['acc', 'vgood'])]\n",
    "    w3, b3, _ = get_best_model(train_X3, train_y3, test_X3, test_y3)\n",
    "    print('predict_y3_types', np.unique(np.sign(test_X3 @ w3 + b3), return_counts=True))\n",
    "    \n",
    "    # Train a SVM classifier, suppose unacceptable is -1 and very good is 1\n",
    "    train_y4 = train_y[~train_y.isin(['acc', 'good'])].replace({'unacc': -1, 'vgood': 1}).values\n",
    "    test_y4 = test_y[~test_y.isin(['acc', 'good'])].replace({'unacc': -1, 'vgood': 1}).values\n",
    "    train_X4 = train_X[~train_y.isin(['acc', 'good'])]\n",
    "    test_X4 = test_X[~test_y.isin(['acc', 'good'])]\n",
    "    w4, b4, _ = get_best_model(train_X4, train_y4, test_X4, test_y4)\n",
    "    print('predict_y4_types', np.unique(np.sign(test_X4 @ w4 + b4), return_counts=True))\n",
    "    \n",
    "    # The final prediction is the majority vote of the four SVM classifiers\n",
    "    def predict(X):\n",
    "        arr = np.array([np.sign(X @ w2 + b2), np.sign(X @ w3 + b3), np.sign(X @ w4 + b4)])\n",
    "        return np.sign(np.sum(np.array([X @ w2 + b2, X @ w3 + b3, X @ w4 + b4]), axis=0))\n",
    "    accuracy = np.mean(predict(test_X) == test_y.replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}).values)\n",
    "    print('predict_types', np.unique(predict(test_X), return_counts=True))\n",
    "    print(f\"Vote Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11709\\anaconda3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_y2_types (array([-1.]), array([163], dtype=int64))\n",
      "predict_y3_types (array([-1.]), array([119], dtype=int64))\n",
      "predict_y4_types (array([-1.,  1.]), array([118,   7], dtype=int64))\n",
      "predict_types (array([-1.]), array([173], dtype=int64))\n",
      "Vote Accuracy: 0.6763005780346821\n"
     ]
    }
   ],
   "source": [
    "#train_general()\n",
    "train_vote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! We plan to train four separate Support Vector Machine (SVM) models with a unique approach.\n",
    "\n",
    "There's four possible values in the target value: A B C D. \n",
    "\n",
    "First Model (Binary Classification for A): In the first model, category A will be labeled as '1', while B, C, and D will be labeled as '-1'. This model's primary objective is to differentiate category A from the others.\n",
    "\n",
    "Next Three Models (One-vs-One Approach): For the subsequent three models, we will employ a one-vs-one strategy where each model will differentiate A from one of the other categories (B, C, or D). Specifically, the models will be: A=1, B=-1; A=1, C=-1; and A=1, D=-1.\n",
    "\n",
    "Accuracy Evaluation in Three Phases:\n",
    "\n",
    "First Phase: we will evaluate the accuracy of the first model (A vs. BCD) independently.\n",
    "\n",
    "Second Phase: The second evaluation will involve the combined accuracy of the next three models. The prediction for each instance will be the majority vote from these models. If the majority vote is inconclusive, we'll randomly select between the two equally probable classes.\n",
    "\n",
    "Third Phase: The final accuracy evaluation will combine all four models. The prediction will again be based on the majority vote. In cases where there is a tie (two '1's and two '-1's), we will randomly select between '-1' and '1' for the final prediction.\n",
    "\n",
    "Do you find this approach feasible and valid for evaluating the performance of SVM models in a multi-class classification problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_train_types (array(['acc', 'good', 'unacc', 'vgood'], dtype=object), array([ 283,   27, 1026,   46], dtype=int64))\n",
      "Train Accuracy: 0.9290882778581766\n",
      "pred_test_types (array(['acc', 'good', 'unacc', 'vgood'], dtype=object), array([ 72,   5, 253,  16], dtype=int64))\n",
      "Test Accuracy: 0.9132947976878613\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[columns], data[6], test_size=0.2, random_state=42)\n",
    "columns = [0,1,2,3,4,5]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data[columns], data[6].replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}), test_size=0.3)\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "# Create a SVM classifier with the OvR strategy\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#train accuracy\n",
    "y_pred = clf.predict(X_train)\n",
    "print('pred_train_types', np.unique(y_pred, return_counts=True))\n",
    "accuracy = np.mean(y_pred == y_train)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "print('pred_test_types', np.unique(y_pred, return_counts=True))\n",
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
