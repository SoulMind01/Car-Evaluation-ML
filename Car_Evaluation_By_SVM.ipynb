{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Dec 07 11:09:27 AM: Encountered unexpected exception importing solver OSQP:\n",
      "ImportError('DLL load failed while importing qdldl: 找不到指定的模块。')\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 25 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   0_high   1728 non-null   int64\n",
      " 1   0_low    1728 non-null   int64\n",
      " 2   0_med    1728 non-null   int64\n",
      " 3   0_vhigh  1728 non-null   int64\n",
      " 4   1_high   1728 non-null   int64\n",
      " 5   1_low    1728 non-null   int64\n",
      " 6   1_med    1728 non-null   int64\n",
      " 7   1_vhigh  1728 non-null   int64\n",
      " 8   2_2      1728 non-null   int64\n",
      " 9   2_3      1728 non-null   int64\n",
      " 10  2_4      1728 non-null   int64\n",
      " 11  2_5more  1728 non-null   int64\n",
      " 12  3_2      1728 non-null   int64\n",
      " 13  3_4      1728 non-null   int64\n",
      " 14  3_more   1728 non-null   int64\n",
      " 15  4_big    1728 non-null   int64\n",
      " 16  4_med    1728 non-null   int64\n",
      " 17  4_small  1728 non-null   int64\n",
      " 18  5_high   1728 non-null   int64\n",
      " 19  5_low    1728 non-null   int64\n",
      " 20  5_med    1728 non-null   int64\n",
      " 21  6_acc    1728 non-null   int64\n",
      " 22  6_good   1728 non-null   int64\n",
      " 23  6_unacc  1728 non-null   int64\n",
      " 24  6_vgood  1728 non-null   int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 337.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_high</th>\n",
       "      <th>0_low</th>\n",
       "      <th>0_med</th>\n",
       "      <th>0_vhigh</th>\n",
       "      <th>1_high</th>\n",
       "      <th>1_low</th>\n",
       "      <th>1_med</th>\n",
       "      <th>1_vhigh</th>\n",
       "      <th>2_2</th>\n",
       "      <th>2_3</th>\n",
       "      <th>...</th>\n",
       "      <th>4_big</th>\n",
       "      <th>4_med</th>\n",
       "      <th>4_small</th>\n",
       "      <th>5_high</th>\n",
       "      <th>5_low</th>\n",
       "      <th>5_med</th>\n",
       "      <th>6_acc</th>\n",
       "      <th>6_good</th>\n",
       "      <th>6_unacc</th>\n",
       "      <th>6_vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_high  0_low  0_med  0_vhigh  1_high  1_low  1_med  1_vhigh  2_2  2_3  \\\n",
       "0      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "1      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "2      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "3      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "4      -1     -1     -1        1      -1     -1     -1        1    1   -1   \n",
       "\n",
       "   ...  4_big  4_med  4_small  5_high  5_low  5_med  6_acc  6_good  6_unacc  \\\n",
       "0  ...     -1     -1        1      -1      1     -1     -1      -1        1   \n",
       "1  ...     -1     -1        1      -1     -1      1     -1      -1        1   \n",
       "2  ...     -1     -1        1       1     -1     -1     -1      -1        1   \n",
       "3  ...     -1      1       -1      -1      1     -1     -1      -1        1   \n",
       "4  ...     -1      1       -1      -1     -1      1     -1      -1        1   \n",
       "\n",
       "   6_vgood  \n",
       "0       -1  \n",
       "1       -1  \n",
       "2       -1  \n",
       "3       -1  \n",
       "4       -1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from the file\n",
    "data = pd.read_csv('car+evaluation/car.data', header=None)\n",
    "data = pd.get_dummies(data)\n",
    "data.iloc[:,:] = data.iloc[:,:].replace({False: -1, True: 1})\n",
    "# Display the first few rows of the dataset\n",
    "data.info()\n",
    "data.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([0, 1, 2, 3, 4, 5], dtype='int32')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\11709\\Desktop\\UCSB\\Optimization\\project\\Car_Evaluation_By_SVM.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/11709/Desktop/UCSB/Optimization/project/Car_Evaluation_By_SVM.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/11709/Desktop/UCSB/Optimization/project/Car_Evaluation_By_SVM.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/11709/Desktop/UCSB/Optimization/project/Car_Evaluation_By_SVM.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_X, test_X, train_y, test_y \u001b[39m=\u001b[39m train_test_split(data[columns], data[\u001b[39m6\u001b[39m]\u001b[39m.\u001b[39mreplace({\u001b[39m'\u001b[39m\u001b[39munacc\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgood\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvgood\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m}), test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/11709/Desktop/UCSB/Optimization/project/Car_Evaluation_By_SVM.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Create an instance of the StandardScaler\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/11709/Desktop/UCSB/Optimization/project/Car_Evaluation_By_SVM.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n",
      "File \u001b[1;32mc:\\Users\\11709\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\11709\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\11709\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([0, 1, 2, 3, 4, 5], dtype='int32')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = [0,1,2,3,4,5]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[columns], data[6].replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}), test_size=0.3)\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.23587708, 0.14915373, ..., 0.47897297, 0.78969293,\n",
       "        0.35780119],\n",
       "       [0.23587708, 1.        , 0.63233666, ..., 0.17620431, 0.23262366,\n",
       "        0.42269216],\n",
       "       [0.14915373, 0.63233666, 1.        , ..., 0.16901332, 0.21107209,\n",
       "        0.47897297],\n",
       "       ...,\n",
       "       [0.47897297, 0.17620431, 0.16901332, ..., 1.        , 0.29457483,\n",
       "        0.32465247],\n",
       "       [0.78969293, 0.23262366, 0.21107209, ..., 0.29457483, 1.        ,\n",
       "        0.50633562],\n",
       "       [0.35780119, 0.42269216, 0.47897297, ..., 0.32465247, 0.50633562,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_kernel(x, y, sigma=1.0):\n",
    "    return np.exp(-np.linalg.norm(x - y) ** 2 / (2 * (sigma ** 2)))\n",
    "def linear_kernel(x, y):\n",
    "    return np.dot(x, y)\n",
    "kernel_matrix = np.array([[gaussian_kernel(x, y) for y in train_X] for x in train_X])\n",
    "kernel_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n"
     ]
    }
   ],
   "source": [
    "alpha = cp.Variable((train_X.shape[0],1))\n",
    "outer_y = train_y.values.reshape((-1,1)) * train_y.values.reshape((-1,1)).T\n",
    "gram = outer_y * kernel_matrix\n",
    "objective = cp.Minimize(-cp.sum(alpha) + 0.5 * cp.quad_form(alpha, cp.psd_wrap(gram)))\n",
    "constraints = [0 <= alpha, alpha <= 1, train_y.values @ alpha == 0]\n",
    "\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(solver = cp.SCS)\n",
    "print(\"problem status: \",problem.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pridiction_type (array([-1.,  1.]), array([197, 322], dtype=int64))\n",
      "Accuracy: 0.6994219653179191\n"
     ]
    }
   ],
   "source": [
    "# support_vector_indices = np.where(alpha.value > 1e-5)[0]\n",
    "# support_vectors = train_X[support_vector_indices]\n",
    "# support_vector_labels = train_y.values[support_vector_indices]\n",
    "\n",
    "test_kernel_matrix = np.array([[gaussian_kernel(x, y) for y in test_X] for x in train_X])\n",
    "predictions = np.sign(np.sum(train_y.values.reshape((-1,1)) * alpha.value * test_kernel_matrix, axis=0))\n",
    "print('pridiction_type',np.unique(predictions,return_counts=True))\n",
    "accuracy = np.mean(predictions == test_y.values)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_list = [0, 0.00001, 0.00005, 0.01, 0.05, 0.1, 1]\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[columns], data[6], test_size=0.1)\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier with a soft margin\n",
    "def train_linear_svm(X_train, y_train, X_test, y_test, gamma = 0.001, norm = 1):\n",
    "    # m is the number of training examples\n",
    "    m = X_train.shape[0]\n",
    "    # n is the number of features\n",
    "    n = X_train.shape[1]\n",
    "    # Need to train k different classifiers\n",
    "    k = y_train.shape[1]\n",
    "    predict_train = np.zeros((k,m,1))\n",
    "    predict_test = np.zeros((k,X_test.shape[0],1))\n",
    "    for i in range(k):\n",
    "        y = y_train[:,i].reshape((-1,1))\n",
    "        w = cp.Variable((n,1))\n",
    "        b = cp.Variable()\n",
    "        eta = cp.Variable((m,1))\n",
    "        norm_eta = cp.norm1(eta) if norm == 1 else cp.norm2(eta)\n",
    "        const = np.ones((m,1))\n",
    "        objective = cp.Minimize(cp.norm2(w) + gamma * norm_eta)\n",
    "        constraints = [cp.multiply(y, X_train @ w - b) >= const - eta, eta >= 0]\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve(verbose=False)\n",
    "        predict_train[i] = np.sign((X_train @ w.value - b.value * const))\n",
    "        predict_test[i] = np.sign((X_test @ w.value - b.value * np.ones((X_test.shape[0],1))))\n",
    "    predict_train = np.squeeze(predict_train.T)\n",
    "    accuracy_train = np.mean(np.all(predict_train == y_train, axis=1))\n",
    "    accuracy_train = round(accuracy_train, 3)\n",
    "    predict_test = np.squeeze(predict_test.T)\n",
    "    accuracy_test = np.mean(np.all(predict_test == y_test, axis=1))\n",
    "    accuracy_test = round(accuracy_test, 3)\n",
    "\n",
    "    return accuracy_train, accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11709\\anaconda3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def train_best_linear_svm(data_path = 'car+evaluation/car.data'):\n",
    "    data = pd.read_csv(data_path, header=None)\n",
    "    data = pd.get_dummies(data)\n",
    "    # Change the false labels to -1 in last 4 columns\n",
    "    data.iloc[:,:] = data.iloc[:,:].replace({False: -1, True: 1})\n",
    "    train_ratio = 0.8\n",
    "    X_train = data.iloc[:int(train_ratio * data.shape[0]),:-4].values\n",
    "    y_train = data.iloc[:int(train_ratio * data.shape[0]),-4:].values\n",
    "    X_test = data.iloc[int(train_ratio * data.shape[0]):,:-4].values\n",
    "    y_test = data.iloc[int(train_ratio * data.shape[0]):,-4:].values\n",
    "    gamma_list = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "    norms = [1, 2]\n",
    "    history = []\n",
    "    for norm in norms:\n",
    "        for gamma in gamma_list:\n",
    "            accuracy_train, accuracy_test = train_linear_svm(X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, gamma = gamma, norm = norm)\n",
    "            history.append([norm, gamma, accuracy_train, accuracy_test])\n",
    "    return history\n",
    "history = train_best_linear_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1          gamma: 0.001      train accuracy: 0.732      test accuracy: 0.572     \n",
      "norm: 1          gamma: 0.003      train accuracy: 0.722      test accuracy: 0.566     \n",
      "norm: 1          gamma: 0.01       train accuracy: 0.874      test accuracy: 0.708     \n",
      "norm: 1          gamma: 0.03       train accuracy: 0.891      test accuracy: 0.647     \n",
      "norm: 1          gamma: 0.1        train accuracy: 0.886      test accuracy: 0.699     \n",
      "norm: 1          gamma: 0.3        train accuracy: 0.886      test accuracy: 0.717     \n",
      "norm: 1          gamma: 1          train accuracy: 0.885      test accuracy: 0.728     \n",
      "norm: 1          gamma: 3          train accuracy: 0.885      test accuracy: 0.734     \n",
      "norm: 1          gamma: 10         train accuracy: 0.885      test accuracy: 0.734     \n",
      "norm: 1          gamma: 30         train accuracy: 0.885      test accuracy: 0.734     \n",
      "norm: 2          gamma: 0.001      train accuracy: 0.732      test accuracy: 0.572     \n",
      "norm: 2          gamma: 0.003      train accuracy: 0.732      test accuracy: 0.572     \n",
      "norm: 2          gamma: 0.01       train accuracy: 0.732      test accuracy: 0.572     \n",
      "norm: 2          gamma: 0.03       train accuracy: 0.732      test accuracy: 0.572     \n",
      "norm: 2          gamma: 0.1        train accuracy: 0.789      test accuracy: 0.584     \n",
      "norm: 2          gamma: 0.3        train accuracy: 0.876      test accuracy: 0.72      \n",
      "norm: 2          gamma: 1          train accuracy: 0.873      test accuracy: 0.723     \n",
      "norm: 2          gamma: 3          train accuracy: 0.87       test accuracy: 0.723     \n",
      "norm: 2          gamma: 10         train accuracy: 0.87       test accuracy: 0.728     \n",
      "norm: 2          gamma: 30         train accuracy: 0.869      test accuracy: 0.728     \n",
      "best test accuracy: 0.734      training accuracy: 0.885      norm: 1          gamma: 3         \n"
     ]
    }
   ],
   "source": [
    "for row in history:\n",
    "    print('norm: {:<10} gamma: {:<10} train accuracy: {:<10} test accuracy: {:<10}'.format(row[0], row[1], row[2], row[3]))\n",
    "# Get best test accuracy's row\n",
    "best_row = history[np.argmax(np.array(history)[:,-1])]\n",
    "print('best test accuracy: {:<10} training accuracy: {:<10} norm: {:<10} gamma: {:<10}'.format(best_row[3], best_row[2], best_row[0], best_row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "def train__vote_svm(X_train, X_test, y_train, y_test, gamma, eta_norm):\n",
    "    # Number of training examples\n",
    "    m = X_train.shape[0]\n",
    "    # Number of features\n",
    "    n = X_train.shape[1]\n",
    "    # Number of classes\n",
    "    k = 4\n",
    "    \n",
    "    # Initialize the predictions matrix\n",
    "    train_predictions = np.zeros((m, k))\n",
    "    test_predictions = np.zeros((X_test.shape[0], k))\n",
    "    \n",
    "    # Train k*(k-1)/2 SVM models\n",
    "    model_index = 0\n",
    "    for i in range(k):\n",
    "        for j in range(i+1, k):\n",
    "            # Select the samples for the current pair of classes\n",
    "            X_train_pair = X_train[np.logical_or(y_train == i, y_train == j)]\n",
    "            y_train_pair = y_train[np.logical_or(y_train == i, y_train == j)]\n",
    "            y_train_pair = np.where(y_train_pair == i, -1, 1)\n",
    "            \n",
    "            X_test_pair = X_test[np.logical_or(y_test == i, y_test == j)]\n",
    "            y_test_pair = y_test[np.logical_or(y_test == i, y_test == j)]\n",
    "            y_test_pair = np.where(y_test_pair == i, -1, 1)\n",
    "            \n",
    "            # Variables\n",
    "            w = cp.Variable((n,))\n",
    "            b = cp.Variable()\n",
    "            eta = cp.Variable((X_train_pair.shape[0],))\n",
    "            \n",
    "            # Constraints\n",
    "            constraints = [cp.multiply(y_train_pair, X_train_pair @ w - b) >= 1 - eta, eta >= 0]\n",
    "            \n",
    "            # Objective function\n",
    "            objective = cp.Minimize(cp.norm2(w) + gamma * cp.norm(eta, eta_norm))\n",
    "            \n",
    "            # Problem definition\n",
    "            problem = cp.Problem(objective, constraints)\n",
    "            \n",
    "            # Solve the problem\n",
    "            problem.solve()\n",
    "            \n",
    "            # Get the optimal values\n",
    "            w_opt = w.value\n",
    "            b_opt = b.value\n",
    "            \n",
    "            # Calculate the predictions for training and test data\n",
    "            train_predictions[:, model_index] = np.sign(X_train @ w_opt - b_opt)\n",
    "            test_predictions[:, model_index] = np.sign(X_test @ w_opt - b_opt)\n",
    "            \n",
    "            model_index += 1\n",
    "    \n",
    "    # Calculate the final predictions by majority voting\n",
    "    train_final_predictions = np.argmax(np.bincount(train_predictions.astype(int), axis=1))\n",
    "    test_final_predictions = np.argmax(np.bincount(test_predictions.astype(int), axis=1))\n",
    "    \n",
    "    # Calculate the accuracies\n",
    "    train_accuracy = np.mean(train_final_predictions == y_train)\n",
    "    test_accuracy = np.mean(test_final_predictions == y_test)\n",
    "    \n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "def train_svm_with_parameters(data_path):\n",
    "    data = pd.read_csv(data_path, header=None)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    \n",
    "    train_ratio = 0.8\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-train_ratio)\n",
    "    \n",
    "    gamma_list = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "    eta_norms = [1, 2]\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for gamma in gamma_list:\n",
    "        for eta_norm in eta_norms:\n",
    "            train_accuracy, test_accuracy = train_vote_svm(X_train, X_test, y_train, y_test, gamma, eta_norm)\n",
    "            history.append({'gamma': gamma, 'eta_norm': eta_norm, 'train_accuracy': train_accuracy, 'test_accuracy': test_accuracy})\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.42701059173376993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11709\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "def train_svm_from_sklearn(data_path = 'car+evaluation/car.data'):\n",
    "    data = pd.read_csv(data_path, header=None)\n",
    "    encoder = OrdinalEncoder()\n",
    "    data = encoder.fit_transform(data)\n",
    "    train_ratio = 0.8\n",
    "    X_train = data[:int(train_ratio * data.shape[0]),:-1]\n",
    "    y_train = data[:int(train_ratio * data.shape[0]),-1:]\n",
    "    X_test = data[int(train_ratio * data.shape[0]):,:-1]\n",
    "    y_test = data[int(train_ratio * data.shape[0]):,-1:]\n",
    "\n",
    "    # Create an instance of the SVM classifier\n",
    "    clf = svm.SVC(gamma='auto')\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Get the predictions\n",
    "    predictions = clf.predict(X_test)\n",
    "    # Get the accuracy\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    return accuracy\n",
    "accuracy = train_svm_from_sklearn()\n",
    "print('test accuracy: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
