{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1  2  3      4     5      6\n",
      "0  vhigh  vhigh  2  2  small   low  unacc\n",
      "1  vhigh  vhigh  2  2  small   med  unacc\n",
      "2  vhigh  vhigh  2  2  small  high  unacc\n",
      "3  vhigh  vhigh  2  2    med   low  unacc\n",
      "4  vhigh  vhigh  2  2    med   med  unacc\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1728 non-null   object\n",
      " 1   1       1728 non-null   object\n",
      " 2   2       1728 non-null   object\n",
      " 3   3       1728 non-null   object\n",
      " 4   4       1728 non-null   object\n",
      " 5   5       1728 non-null   object\n",
      " 6   6       1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from the file\n",
    "data = pd.read_csv('car+evaluation/car.data', header=None)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "data.info()\n",
    "data[6].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all columns to numeric\n",
    "for i in range(0, 6):\n",
    "    data[i] = pd.Categorical(data[i])\n",
    "    data[i] = data[i].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.66666667, 0.5       , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.5       ],\n",
       "       [0.33333333, 1.        , 1.        , 0.5       , 0.        ,\n",
       "        0.5       ],\n",
       "       ...,\n",
       "       [1.        , 0.66666667, 0.33333333, 1.        , 0.5       ,\n",
       "        1.        ],\n",
       "       [0.66666667, 1.        , 0.33333333, 0.        , 0.5       ,\n",
       "        0.5       ],\n",
       "       [0.66666667, 0.66666667, 1.        , 0.5       , 0.5       ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = [0,1,2,3,4,5]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[columns], data[6].replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}), test_size=0.3)\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.39984965, 0.53526143, ..., 0.42269216, 0.49246429,\n",
       "        0.45308902],\n",
       "       [0.39984965, 1.        , 0.53526143, ..., 0.33846543, 0.78969293,\n",
       "        0.37302452],\n",
       "       [0.53526143, 0.53526143, 1.        , ..., 0.41686202, 0.58991444,\n",
       "        0.69690156],\n",
       "       ...,\n",
       "       [0.42269216, 0.33846543, 0.41686202, ..., 1.        , 0.47897297,\n",
       "        0.66846063],\n",
       "       [0.49246429, 0.78969293, 0.58991444, ..., 0.47897297, 1.        ,\n",
       "        0.58991444],\n",
       "       [0.45308902, 0.37302452, 0.69690156, ..., 0.66846063, 0.58991444,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_kernel(x, y, sigma=1.0):\n",
    "    return np.exp(-np.linalg.norm(x - y) ** 2 / (2 * (sigma ** 2)))\n",
    "def linear_kernel(x, y):\n",
    "    return np.dot(x, y)\n",
    "kernel_matrix = np.array([[gaussian_kernel(x, y) for y in train_X] for x in train_X])\n",
    "kernel_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outer_y=np.outer(train_y, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.39984965, -0.53526143, ...,  0.42269216,\n",
       "        -0.49246429,  0.45308902],\n",
       "       [-0.39984965,  1.        ,  0.53526143, ..., -0.33846543,\n",
       "         0.78969293, -0.37302452],\n",
       "       [-0.53526143,  0.53526143,  1.        , ..., -0.41686202,\n",
       "         0.58991444, -0.69690156],\n",
       "       ...,\n",
       "       [ 0.42269216, -0.33846543, -0.41686202, ...,  1.        ,\n",
       "        -0.47897297,  0.66846063],\n",
       "       [-0.49246429,  0.78969293,  0.58991444, ..., -0.47897297,\n",
       "         1.        , -0.58991444],\n",
       "       [ 0.45308902, -0.37302452, -0.69690156, ...,  0.66846063,\n",
       "        -0.58991444,  1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_y * kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem status:  optimal\n"
     ]
    }
   ],
   "source": [
    "alpha = cp.Variable((train_X.shape[0],1))\n",
    "outer_y = train_y.values.reshape((-1,1)) * train_y.values.reshape((-1,1)).T\n",
    "gram = outer_y * kernel_matrix\n",
    "objective = cp.Minimize(-cp.sum(alpha) + 0.5 * cp.quad_form(alpha, cp.psd_wrap(gram)))\n",
    "constraints = [0 <= alpha, alpha <= 1, train_y.values @ alpha == 0]\n",
    "\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(solver = cp.SCS)\n",
    "print(\"problem status: \",problem.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7745664739884393\n"
     ]
    }
   ],
   "source": [
    "# support_vector_indices = np.where(alpha.value > 1e-5)[0]\n",
    "# support_vectors = train_X[support_vector_indices]\n",
    "# support_vector_labels = train_y.values[support_vector_indices]\n",
    "\n",
    "test_kernel_matrix = np.array([[gaussian_kernel(x, y) for y in test_X] for x in train_X])\n",
    "predictions = np.sign(np.sum(train_y.values.reshape((-1,1)) * alpha.value * test_kernel_matrix, axis=0))\n",
    "\n",
    "accuracy = np.mean(predictions == test_y.values)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier\n",
    "def svm(X, y, gamma, regularization_type):\n",
    "    y = y.reshape((-1,1))\n",
    "    # Define the SVM variables\n",
    "    w = cp.Variable((X.shape[1],1))\n",
    "    b = cp.Variable()\n",
    "    n = cp.Variable((X.shape[0],1))\n",
    "    const = np.ones((X.shape[0],1))\n",
    "\n",
    "    # Choose the regularization type\n",
    "    w_norm = cp.norm2(w)\n",
    "    if regularization_type == 1:\n",
    "        w_norm = cp.norm1(w)\n",
    "\n",
    "    # Define the SVM constraints\n",
    "    constraints = [cp.multiply(y, (X @ w + b)) >= const - n, n >= 0]\n",
    "\n",
    "    # Define the objective function to minimize the sum of the regularization term\n",
    "    objective = cp.Minimize(w_norm + gamma * cp.norm1(n))\n",
    "\n",
    "    # Define the SVM problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    # Solve the SVM problem\n",
    "    problem.solve()\n",
    "    return w.value, b.value\n",
    "\n",
    "def get_accuracy(X, y, w, b):\n",
    "    y_pred = np.sign(X @ w + b)\n",
    "    return np.mean(y_pred == y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier\n",
    "def svm(X, y, gamma, regularization_type):\n",
    "    y = np.array(y).reshape((-1,1))\n",
    "    # Define the SVM variables\n",
    "    w = cp.Variable((X.shape[1],1))\n",
    "    b = cp.Variable()\n",
    "    n = cp.Variable((X.shape[0],1))\n",
    "    const = np.ones((X.shape[0],1))\n",
    "\n",
    "    # Choose the regularization type\n",
    "    w_norm = cp.norm1(w)\n",
    "    if regularization_type == 2:\n",
    "        w_norm = cp.norm2(w)\n",
    "\n",
    "    # Define the SVM constraints\n",
    "    constraints = [cp.multiply(y, (X @ w + b)) >= const - n, n >= 0]\n",
    "\n",
    "    # Define the objective function to minimize the sum of the regularization term\n",
    "    objective = cp.Minimize(w_norm + gamma * cp.norm1(n))\n",
    "\n",
    "    # Define the SVM problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    # Solve the SVM problem\n",
    "    problem.solve(verbose=False)\n",
    "    return w.value, b.value\n",
    "\n",
    "def get_accuracy(X, y, w, b):\n",
    "    y_pred = np.sign(X @ w + b)\n",
    "    return np.mean(y_pred == y)\n",
    "\n",
    "def get_best_model(X, y, X_test, y_test, gamma_list, regularization_type):\n",
    "    best_accuracy = 0\n",
    "    best_w = None\n",
    "    best_b = None\n",
    "\n",
    "    for gamma in gamma_list:\n",
    "        w, b = svm(X, y, gamma, regularization_type)\n",
    "        accuracy = get_accuracy(X_test, y_test, w, b)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_gamma = gamma\n",
    "            best_w = w\n",
    "            best_b = b\n",
    "    return best_w, best_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data.iloc[:,:6], data.iloc[:,6], test_size=0.2, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different values of gamma\n",
    "def train_general(gamma_list, regularization_type):\n",
    "    # Train a SVM classifier, suppose acceptable is -1 and unacceptable, good, very good are 1\n",
    "    train_y1 = train_y.replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1})\n",
    "    test_y1 = test_y.replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1})\n",
    "    best_w1, best_b1 = get_best_model(train_X.values, train_y1.values, test_X.values, test_y1.values, gamma_list, regularization_type)\n",
    "    accuracy1 = get_accuracy(test_X.values, test_y1.values, best_w1, best_b1)\n",
    "    print(f\"General Accuracy: {accuracy1}\")\n",
    "    return best_w1, best_b1\n",
    "\n",
    "def train_vote(gamma, regularization_type):\n",
    "    # Train a SVM classifier, suppose unacceptable is -1 and acceptable is 1\n",
    "    train_y2 = train_y[~train_y.isin(['good', 'vgood'])].replace({'unacc': -1, 'acc': 1})\n",
    "    test_y2 = test_y[~test_y.isin(['good', 'vgood'])].replace({'unacc': -1, 'acc': 1})\n",
    "    w2, b2 = get_best_model(train_X[~train_y.isin(['good', 'vgood'])].values, train_y2.values, test_X[~test_y.isin(['good', 'vgood'])].values, test_y2.values, gamma, regularization_type)\n",
    "    # Train a SVM classifier, suppose unacceptable is -1 and good is 1\n",
    "    train_y3 = train_y[~train_y.isin(['acc', 'vgood'])].replace({'unacc': -1, 'good': 1})\n",
    "    test_y3 = test_y[~test_y.isin(['acc', 'vgood'])].replace({'unacc': -1, 'good': 1})\n",
    "    w3, b3 = get_best_model(train_X[~train_y.isin(['acc', 'vgood'])].values, train_y3.values, test_X[~test_y.isin(['acc', 'vgood'])].values, test_y3.values, gamma, regularization_type)\n",
    "    # Train a SVM classifier, suppose acceptable is -1 and unacceptable, very good is 1\n",
    "    train_y4 = train_y[~train_y.isin(['acc', 'good'])].replace({'unacc': -1, 'vgood': 1})\n",
    "    test_y4 = test_y[~test_y.isin(['acc', 'good'])].replace({'unacc': -1, 'vgood': 1})\n",
    "    w4, b4 = get_best_model(train_X[~train_y.isin(['acc', 'good'])].values, train_y4.values, test_X[~test_y.isin(['acc', 'good'])].values, test_y4.values, gamma, regularization_type)\n",
    "    \n",
    "    # The final prediction is the majority vote of the four SVM classifiers\n",
    "    def predict(X):\n",
    "        return np.sign(np.sum(np.array([X @ w2 + b2, X @ w3 + b3, X @ w4 + b4]), axis=0))\n",
    "    accuracy = np.mean(predict(test_X.values) == test_y.replace({'unacc': -1, 'acc': 1, 'good': 1, 'vgood': 1}).values)\n",
    "    print(f\"Vote Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Accuracy: 0.708092485549133\n",
      "General Accuracy: 0.708092485549133\n",
      "Vote Accuracy: 0.708092485549133\n",
      "Vote Accuracy: 0.708092485549133\n"
     ]
    }
   ],
   "source": [
    "gamma_list = [0.01, 0.1, 1, 5, 10, 50]\n",
    "train_general(gamma_list, 1)\n",
    "train_general(gamma_list, 2)\n",
    "train_vote(gamma_list, 1)\n",
    "train_vote(gamma_list, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! We plan to train four separate Support Vector Machine (SVM) models with a unique approach.\n",
    "\n",
    "There's four possible values in the target value: A B C D. \n",
    "\n",
    "First Model (Binary Classification for A): In the first model, category A will be labeled as '1', while B, C, and D will be labeled as '-1'. This model's primary objective is to differentiate category A from the others.\n",
    "\n",
    "Next Three Models (One-vs-One Approach): For the subsequent three models, we will employ a one-vs-one strategy where each model will differentiate A from one of the other categories (B, C, or D). Specifically, the models will be: A=1, B=-1; A=1, C=-1; and A=1, D=-1.\n",
    "\n",
    "Accuracy Evaluation in Three Phases:\n",
    "\n",
    "First Phase: we will evaluate the accuracy of the first model (A vs. BCD) independently.\n",
    "\n",
    "Second Phase: The second evaluation will involve the combined accuracy of the next three models. The prediction for each instance will be the majority vote from these models. If the majority vote is inconclusive, we'll randomly select between the two equally probable classes.\n",
    "\n",
    "Third Phase: The final accuracy evaluation will combine all four models. The prediction will again be based on the majority vote. In cases where there is a tie (two '1's and two '-1's), we will randomly select between '-1' and '1' for the final prediction.\n",
    "\n",
    "Do you find this approach feasible and valid for evaluating the performance of SVM models in a multi-class classification problem?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
